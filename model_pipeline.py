# coding: utf-8


# -*- coding: utf-8 -*-
"""model_pipeline_LGBM.ipynb

Automatically generated by Colab.
"""

import pandas as pd
import numpy as np
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from category_encoders.binary import BinaryEncoder
import lightgbm as lgb
import warnings

def display_basic_info(df, name):
    """Affiche les informations de base sur le dataset."""
    print(f"\nDataset: {name}")
    print("-" * 40)
    print(f"Shape: {df.shape}")
    print("\nData Types:")
    print(df.dtypes)
    print("\nMissing Values:")
    print(df.isnull().sum())
    print("\nSummary Statistics:")
    print(df.describe())


def plot_outliers(df, title):
    """Affiche les boxplots pour visualiser les outliers."""
    plt.figure(figsize=(12, 6))
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    if len(numeric_cols) > 0:
        sns.boxplot(data=df[numeric_cols])
        plt.xticks(rotation=90)
        plt.title(title)
        plt.show()
    else:
        print(f"Aucune colonne num√©rique trouv√©e pour {title}")


def impute_outliers(df, columns):
    """Impute les outliers en utilisant la m√©thode des quartiles (IQR) et les remplace par la moyenne."""
    for column in columns:
        if column in df.columns:
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            mean_value = df[column].mean()
            df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), mean_value, df[column])
    return df
def prepare_data(train_path="~/ela_chaabane_4ds2_ml_project/churn-bigml-80.csv", test_path="~/ela_chaabane_4ds2_ml_project/churn-bigml-20.csv"):
    """Charge, nettoie et pr√©pare les donn√©es pour l'entra√Ænement et l'√©valuation."""

    df_80 = pd.read_csv(train_path)
    df_20 = pd.read_csv(test_path)

    # Remplir les valeurs manquantes avec la moyenne pour les colonnes num√©riques
    for col in df_80.select_dtypes(include=["float64", "int64"]).columns:
        df_80[col].fillna(df_80[col].mean(), inplace=True)
        df_20[col].fillna(df_20[col].mean(), inplace=True)

    # Liste des colonnes num√©riques pour l'imputation des outliers
    numerical_columns = [
        "Account length",
        "Number vmail messages",
        "Total day minutes",
        "Total day calls",
        "Total day charge",
        "Total eve minutes",
        "Total eve calls",
        "Total eve charge",
        "Total night minutes",
        "Total night calls",
        "Total night charge",
        "Total intl minutes",
        "Total intl calls",
        "Total intl charge",
        "Customer service calls",
    ]

    # Imputation des outliers avec la moyenne
    df_80 = impute_outliers(df_80, numerical_columns)
    df_20 = impute_outliers(df_20, numerical_columns)

    # Encodage des variables cat√©goriques
    categorical_features = ["International plan", "Voice mail plan"]
    encoder = OrdinalEncoder()
    df_80[categorical_features] = encoder.fit_transform(df_80[categorical_features])
    df_20[categorical_features] = encoder.transform(df_20[categorical_features])

    # Encodage binaire de "State"
    if "State" in df_80.columns:
        state_encoder = BinaryEncoder(cols=["State"])
        df_80 = state_encoder.fit_transform(df_80)
        df_20 = state_encoder.transform(df_20)

    # Convertir la colonne "Churn" en entier (0 ou 1)
    df_80["Churn"] = df_80["Churn"].astype(int)
    df_20["Churn"] = df_20["Churn"].astype(int)

    # Normalisation des donn√©es avec MinMaxScaler
    scaler = MinMaxScaler()
    df_80_scaled = pd.DataFrame(scaler.fit_transform(df_80), columns=df_80.columns)
    df_20_scaled = pd.DataFrame(scaler.transform(df_20), columns=df_20.columns)

    # Suppression des caract√©ristiques hautement corr√©l√©es
    features_to_remove = [
        "Total day charge",
        "Total eve charge",
        "Total night charge",
        "Total intl charge",
    ]
    df_80_scaled.drop(columns=features_to_remove, inplace=True, errors="ignore")
    df_20_scaled.drop(columns=features_to_remove, inplace=True, errors="ignore")

    # S√©paration en features et labels
    X_train = df_80_scaled.drop(columns=["Churn"])
    y_train = df_80_scaled["Churn"]
    X_test = df_20_scaled.drop(columns=["Churn"])
    y_test = df_20_scaled["Churn"]

    return X_train, y_train, X_test, y_test


import mlflow
import mlflow.sklearn
# Configurer l'URI du serveur MLflow
mlflow.set_tracking_uri("http://localhost:5000")

def train_model(X_train, y_train):
    """Entra√Æne un mod√®le de classification LightGBM et enregistre les r√©sultats avec MLflow."""
    print("\nüîÑ Entra√Ænement du mod√®le LightGBM...")

    # D√©marrer une run MLflow
    with mlflow.start_run():
        # D√©finir les hyperparam√®tres
        params = {
            "n_estimators": 100,
            "random_state": 42,
            "learning_rate": 0.05,
            "max_depth": 5
        }

        # Entra√Æner le mod√®le
        model = lgb.LGBMClassifier(**params)
        model.fit(X_train, y_train)

        # Enregistrer les hyperparam√®tres dans MLflow
        mlflow.log_params(params)

        # Enregistrer les m√©triques
        y_pred_train = model.predict(X_train)
        accuracy_train = accuracy_score(y_train, y_pred_train)
        mlflow.log_metric("train_accuracy", accuracy_train)

        # Enregistrer le mod√®le avec un exemple d'entr√©e
        mlflow.sklearn.log_model(model, "model", input_example=X_train[:1])

        print("‚úÖ Mod√®le entra√Æn√© avec succ√®s et enregistr√© dans MLflow !")
    return model

def evaluate_model(model, X_test, y_test):
    """√âvalue le mod√®le sur les donn√©es de test et enregistre les r√©sultats avec MLflow."""
    print("\nüìä √âvaluation du mod√®le...")

    # D√©marrer une run MLflow
    with mlflow.start_run():
        # Faire des pr√©dictions
        y_pred = model.predict(X_test)

        # Calculer l'accuracy
        accuracy = accuracy_score(y_test, y_pred)
        mlflow.log_metric("test_accuracy", accuracy)

        # Enregistrer le rapport de classification
        report = classification_report(y_test, y_pred, target_names=['No Churn', 'Churn'])
        mlflow.log_text(report, "classification_report.txt")

        print("\nüîç Rapport de classification :")
        print(report)

        return accuracy

def save_model(model, filename="churn_model.joblib"):
    """Sauvegarde le mod√®le dans un fichier."""
    joblib.dump(model, filename)
    print(f"\nüíæ Mod√®le sauvegard√© sous {filename}")


def load_model(filename="churn_model.joblib"):
    """Charge un mod√®le √† partir d'un fichier."""
    print(f"\nüìÇ Chargement du mod√®le depuis {filename}...")
    return joblib.load(filename)






