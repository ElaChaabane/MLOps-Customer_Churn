#!/usr/bin/env python
# coding: utf-8


# -*- coding: utf-8 -*-
"""model_pipeline_LGBM.ipynb

Automatically generated by Colab.
"""

import pandas as pd
import numpy as np
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from category_encoders.binary import BinaryEncoder
import lightgbm as lgb


def display_basic_info(df, name):
    """Affiche les informations de base sur le dataset."""
    print(f"\nDataset: {name}")
    print("-" * 40)
    print(f"Shape: {df.shape}")
    print("\nData Types:")
    print(df.dtypes)
    print("\nMissing Values:")
    print(df.isnull().sum())
    print("\nSummary Statistics:")
    print(df.describe())


def plot_outliers(df, title):
    """Affiche les boxplots pour visualiser les outliers."""
    plt.figure(figsize=(12, 6))
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    if len(numeric_cols) > 0:
        sns.boxplot(data=df[numeric_cols])
        plt.xticks(rotation=90)
        plt.title(title)
        plt.show()
    else:
        print(f"Aucune colonne num√©rique trouv√©e pour {title}")


def impute_outliers(df, columns):
    """Impute les outliers en utilisant la m√©thode des quartiles (IQR) et les remplace par la moyenne."""
    for column in columns:
        if column in df.columns:
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            mean_value = df[column].mean()
            df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), mean_value, df[column])
    return df


def prepare_data(train_path="churn_80.csv", test_path="churn_20.csv"):
    """Charge, nettoie et pr√©pare les donn√©es pour l'entra√Ænement et l'√©valuation."""

    df_80 = pd.read_csv(train_path)
    df_20 = pd.read_csv(test_path)

    display_basic_info(df_80, 'churn-bigml-80')
    display_basic_info(df_20, 'churn-bigml-20')

    for col in df_80.select_dtypes(include=['float64', 'int64']).columns:
        df_80[col].fillna(df_80[col].mean(), inplace=True)
        df_20[col].fillna(df_20[col].mean(), inplace=True)

    plot_outliers(df_80, "Outliers dans churn-bigml-80 avant imputation")
    plot_outliers(df_20, "Outliers dans churn-bigml-20 avant imputation")

    numerical_columns = [
        'Account length', 'Number vmail messages', 'Total day minutes', 'Total day calls',
        'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge',
        'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes',
        'Total intl calls', 'Total intl charge', 'Customer service calls'
    ]

    df_80 = impute_outliers(df_80, numerical_columns)
    df_20 = impute_outliers(df_20, numerical_columns)

    plot_outliers(df_80, "Outliers dans churn-bigml-80 apr√®s imputation")
    plot_outliers(df_20, "Outliers dans churn-bigml-20 apr√®s imputation")

    categorical_features = ['International plan', 'Voice mail plan']

    encoder = OrdinalEncoder()
    df_80[categorical_features] = encoder.fit_transform(df_80[categorical_features])
    df_20[categorical_features] = encoder.transform(df_20[categorical_features])

    if 'State' in df_80.columns:
        state_encoder = BinaryEncoder(cols=['State'])
        df_80 = state_encoder.fit_transform(df_80)
        df_20 = state_encoder.transform(df_20)

    df_80['Churn'] = df_80['Churn'].astype(int)
    df_20['Churn'] = df_20['Churn'].astype(int)

    scaler = MinMaxScaler()
    scaled_80 = scaler.fit_transform(df_80)
    scaled_20 = scaler.transform(df_20)

    df_80_scaled = pd.DataFrame(scaled_80, columns=df_80.columns)
    df_20_scaled = pd.DataFrame(scaled_20, columns=df_20.columns)

    features_to_remove = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']
    df_80_scaled.drop(columns=features_to_remove, inplace=True, errors='ignore')
    df_20_scaled.drop(columns=features_to_remove, inplace=True, errors='ignore')

    X_train = df_80_scaled.drop(columns=['Churn'])
    y_train = df_80_scaled['Churn']
    X_test = df_20_scaled.drop(columns=['Churn'])
    y_test = df_20_scaled['Churn']

    return X_train, y_train, X_test, y_test


def train_model(X_train, y_train):
    """Entra√Æne un mod√®le de classification LightGBM."""
    print("\nüîÑ Entra√Ænement du mod√®le LightGBM...")
    model = lgb.LGBMClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    print("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
    return model


def evaluate_model(model, X_test, y_test):
    """√âvalue le mod√®le sur les donn√©es de test avec des m√©triques d√©taill√©es."""
    print("\nüìä √âvaluation du mod√®le...")
    y_pred = model.predict(X_test)

    # Accuracy metric
    accuracy = accuracy_score(y_test, y_pred)
    print(f"‚úÖ Accuracy du mod√®le : {accuracy:.2f}")

    # Classification report for detailed metrics
    report = classification_report(y_test, y_pred, target_names=['No Churn', 'Churn'])
    print("\nüîç Rapport de classification :")
    print(report)

    return accuracy


def save_model(model, filename="churn_model.pkl"):
    """Sauvegarde le mod√®le dans un fichier."""
    joblib.dump(model, filename)
    print(f"\nüíæ Mod√®le sauvegard√© sous {filename}")


def load_model(filename="churn_model.pkl"):
    """Charge un mod√®le √† partir d'un fichier."""
    print(f"\nüìÇ Chargement du mod√®le depuis {filename}...")
    return joblib.load(filename)






#!/usr/bin/env python
# coding: utf-8


# -*- coding: utf-8 -*-
"""model_pipeline_LGBM.ipynb

Automatically generated by Colab.
"""

import pandas as pd
import numpy as np
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from category_encoders.binary import BinaryEncoder
import lightgbm as lgb


def display_basic_info(df, name):
    """Affiche les informations de base sur le dataset."""
    print(f"\nDataset: {name}")
    print("-" * 40)
    print(f"Shape: {df.shape}")
    print("\nData Types:")
    print(df.dtypes)
    print("\nMissing Values:")
    print(df.isnull().sum())
    print("\nSummary Statistics:")
    print(df.describe())


def plot_outliers(df, title):
    """Affiche les boxplots pour visualiser les outliers."""
    plt.figure(figsize=(12, 6))
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    if len(numeric_cols) > 0:
        sns.boxplot(data=df[numeric_cols])
        plt.xticks(rotation=90)
        plt.title(title)
        plt.show()
    else:
        print(f"Aucune colonne num√©rique trouv√©e pour {title}")


def impute_outliers(df, columns):
    """Impute les outliers en utilisant la m√©thode des quartiles (IQR) et les remplace par la moyenne."""
    for column in columns:
        if column in df.columns:
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            mean_value = df[column].mean()
            df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), mean_value, df[column])
    return df


def prepare_data(train_path="churn_80.csv", test_path="churn_20.csv"):
    """Charge, nettoie et pr√©pare les donn√©es pour l'entra√Ænement et l'√©valuation."""

    df_80 = pd.read_csv(train_path)
    df_20 = pd.read_csv(test_path)

    display_basic_info(df_80, 'churn-bigml-80')
    display_basic_info(df_20, 'churn-bigml-20')

    for col in df_80.select_dtypes(include=['float64', 'int64']).columns:
        df_80[col].fillna(df_80[col].mean(), inplace=True)
        df_20[col].fillna(df_20[col].mean(), inplace=True)

    plot_outliers(df_80, "Outliers dans churn-bigml-80 avant imputation")
    plot_outliers(df_20, "Outliers dans churn-bigml-20 avant imputation")

    numerical_columns = [
        'Account length', 'Number vmail messages', 'Total day minutes', 'Total day calls',
        'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge',
        'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes',
        'Total intl calls', 'Total intl charge', 'Customer service calls'
    ]

    df_80 = impute_outliers(df_80, numerical_columns)
    df_20 = impute_outliers(df_20, numerical_columns)

    plot_outliers(df_80, "Outliers dans churn-bigml-80 apr√®s imputation")
    plot_outliers(df_20, "Outliers dans churn-bigml-20 apr√®s imputation")

    categorical_features = ['International plan', 'Voice mail plan']

    encoder = OrdinalEncoder()
    df_80[categorical_features] = encoder.fit_transform(df_80[categorical_features])
    df_20[categorical_features] = encoder.transform(df_20[categorical_features])

    if 'State' in df_80.columns:
        state_encoder = BinaryEncoder(cols=['State'])
        df_80 = state_encoder.fit_transform(df_80)
        df_20 = state_encoder.transform(df_20)

    df_80['Churn'] = df_80['Churn'].astype(int)
    df_20['Churn'] = df_20['Churn'].astype(int)

    scaler = MinMaxScaler()
    scaled_80 = scaler.fit_transform(df_80)
    scaled_20 = scaler.transform(df_20)

    df_80_scaled = pd.DataFrame(scaled_80, columns=df_80.columns)
    df_20_scaled = pd.DataFrame(scaled_20, columns=df_20.columns)

    features_to_remove = ['Total day charge', 'Total eve charge', 'Total night charge', 'Total intl charge']
    df_80_scaled.drop(columns=features_to_remove, inplace=True, errors='ignore')
    df_20_scaled.drop(columns=features_to_remove, inplace=True, errors='ignore')

    X_train = df_80_scaled.drop(columns=['Churn'])
    y_train = df_80_scaled['Churn']
    X_test = df_20_scaled.drop(columns=['Churn'])
    y_test = df_20_scaled['Churn']

    return X_train, y_train, X_test, y_test


def train_model(X_train, y_train):
    """Entra√Æne un mod√®le de classification LightGBM."""
    print("\nüîÑ Entra√Ænement du mod√®le LightGBM...")
    model = lgb.LGBMClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    print("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
    return model


def evaluate_model(model, X_test, y_test):
    """√âvalue le mod√®le sur les donn√©es de test avec des m√©triques d√©taill√©es."""
    print("\nüìä √âvaluation du mod√®le...")
    y_pred = model.predict(X_test)

    # Accuracy metric
    accuracy = accuracy_score(y_test, y_pred)
    print(f"‚úÖ Accuracy du mod√®le : {accuracy:.2f}")

    # Classification report for detailed metrics
    report = classification_report(y_test, y_pred, target_names=['No Churn', 'Churn'])
    print("\nüîç Rapport de classification :")
    print(report)

    return accuracy


def save_model(model, filename="churn_model.pkl"):
    """Sauvegarde le mod√®le dans un fichier."""
    joblib.dump(model, filename)
    print(f"\nüíæ Mod√®le sauvegard√© sous {filename}")


def load_model(filename="churn_model.pkl"):
    """Charge un mod√®le √† partir d'un fichier."""
    print(f"\nüìÇ Chargement du mod√®le depuis {filename}...")
    return joblib.load(filename)







